{"id": "multiple_0", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_1", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_2", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_3", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_4", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_5", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_6", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_7", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_8", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_9", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_10", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_11", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_12", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_13", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_14", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_15", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_16", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_17", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_18", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_19", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_20", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_21", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_22", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_23", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_24", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_25", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_26", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_27", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_28", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_29", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_30", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_31", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_32", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_33", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_34", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_35", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_36", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_37", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_38", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_39", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_40", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_41", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_42", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_43", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_44", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_45", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_46", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_47", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_48", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_49", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_50", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_51", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_52", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_53", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_54", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_55", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_56", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_57", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_58", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_59", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_60", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_61", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_62", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_63", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_64", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_65", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_66", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_67", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_68", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_69", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_70", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_71", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_72", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_73", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_74", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_75", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_76", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_77", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_78", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_79", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_80", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_81", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_82", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_83", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_84", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_85", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_86", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_87", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_88", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_89", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_90", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_91", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_92", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_93", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_94", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_95", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_96", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_97", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_98", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_99", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_100", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_101", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_102", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_103", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_104", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_105", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_106", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_107", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_108", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_109", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_110", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_111", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_112", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_113", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[1].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[1].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_114", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_115", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_116", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_117", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_118", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_119", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_120", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_121", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_122", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_123", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_124", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_125", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_126", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_127", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_128", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_129", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_130", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_131", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_132", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_133", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_134", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_135", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_136", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_137", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_138", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_139", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_140", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_141", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_142", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_143", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_144", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_145", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_146", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_147", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_148", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_149", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_150", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_151", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_152", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_153", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_154", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_155", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_156", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_157", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_158", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_159", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_160", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_161", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_162", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_163", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_164", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_165", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_166", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_167", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_168", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_169", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_170", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_171", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_172", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_173", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_174", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_175", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_176", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_177", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_178", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_179", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_180", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_181", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_182", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_183", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_184", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_185", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_186", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_187", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_188", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_189", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_190", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_191", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_192", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_193", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_194", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_195", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_196", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_197", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_198", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
{"id": "multiple_199", "result": "Error during inference: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}", "traceback": "Traceback (most recent call last):\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/_llm_response_generation.py\", line 175, in multi_threaded_inference\n    result, metadata = handler.inference(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 84, in inference\n    return self.inference_single_turn_FC(test_entry, include_input_log)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/base_handler.py\", line 695, in inference_single_turn_FC\n    api_response, query_latency = self._query_FC(inference_data)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 68, in _query_FC\n    return self.generate_with_backoff(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 336, in wrapped_f\n    return copy(f, *args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 475, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 376, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/sw/spack/deltas11-2023-03/apps/linux-rhel8-zen3/gcc-11.4.0/python-3.12.1-ahcgi2c/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 478, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/utils.py\", line 606, in wrapped\n    return func(*args, **inner_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/projects/bfdz/zluo8/translate/bfcl/bfcl_eval/model_handler/api_inference/deepseek.py\", line 45, in generate_with_backoff\n    api_response = self.client.chat.completions.create(**kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/nvme/bfdz/zluo8/translate/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n"}
