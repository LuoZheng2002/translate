Processing config: Config(model=<LocalModel.QWEN_2_5_7B_INSTRUCT: 'Qwen/Qwen2.5-7B-Instruct'>, translate_mode=NotTranslated(), add_noise_mode=<AddNoiseMode.NO_NOISE: 1>)
Warning: some test cases already exist in inference result file. Skipping 200 cases.
Creating pipeline for Qwen/Qwen2.5-7B-Instruct
Loading local model: Qwen/Qwen2.5-7B-Instruct
Local model loaded and generator is ready.
Post-processing: Copied 200 results without modification (DONT_POST_PROCESS)
Score result written to result/score/BFCL_v4_multiple_qwen2_5_7b.json: {'accuracy': 0.94, 'total_cases': 200, 'correct_cases': 188}
Completed processing for config: Config(model=<LocalModel.QWEN_2_5_7B_INSTRUCT: 'Qwen/Qwen2.5-7B-Instruct'>, translate_mode=NotTranslated(), add_noise_mode=<AddNoiseMode.NO_NOISE: 1>)
Processing config: Config(model=<LocalModel.QWEN_2_5_14B_INSTRUCT: 'Qwen/Qwen2.5-14B-Instruct'>, translate_mode=NotTranslated(), add_noise_mode=<AddNoiseMode.NO_NOISE: 1>)
File result/inference_raw/BFCL_v4_multiple_qwen2_5_14b.json not found. It will be created.
Switching from Qwen/Qwen2.5-7B-Instruct to Qwen/Qwen2.5-14B-Instruct
Freeing memory from previous model...
Memory freed. Loading new model...
Creating pipeline for Qwen/Qwen2.5-14B-Instruct
Loading local model: Qwen/Qwen2.5-14B-Instruct
